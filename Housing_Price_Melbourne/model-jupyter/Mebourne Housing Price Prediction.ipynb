{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6711924d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <h1 align=\"center\">Mebourne Housing Price Prediction</h1>\n",
    "    <h3 align=\"center\">Interactive Dashboards in Python - Streamlit Part</h3>\n",
    "    <h3 align=\"center\">Updated Aug. 2023</h3>\n",
    "    <a align=\"center\" href=\"https://www.linkedin.com/in/hsheikh7/\" >\n",
    "        <h3 align=\"center\">Hassan Sheikh</h3>\n",
    "    </a>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820e0fdd",
   "metadata": {},
   "source": [
    "# **Melbourne Housing Price Prediction Project**\n",
    "\n",
    "## About\n",
    "\n",
    "I got really excited when I brought this model to life in a Streamlit app. With this app, users could easily input data, receiving real-time predictions for housing prices as a result.\n",
    "\n",
    "## Data Source\n",
    "\n",
    "The invaluable dataset for this project hailed from Kaggle's treasure trove. See it here: [Melbourne Housing Snapshot dataset](https://www.kaggle.com/datasets/dansbecker/melbourne-housing-snapshot/code?select=melb_data.csv) \n",
    "\n",
    "## Workflow\n",
    "\n",
    "1. **Data Collection:** The project's foundation was laid with the acquisition of the Melbourne Housing Snapshot dataset from Kaggle.\n",
    "\n",
    "2. **Data Preprocessing:** The dataset underwent careful preprocessing to address missing values, normalize features, and sculpt categorical variables into a form suitable for training.\n",
    "\n",
    "3. **Model Building:** I used RandomForestRegressor to build a good model. \n",
    "\n",
    "4. **Model Evaluation:** Mean Squared Error shows performance of model.\n",
    "\n",
    "5. **Model Deployment:** When the model was OK, I saved it by Joblib library, then I load it in VSCode area.\n",
    "\n",
    "6. **Streamlit Fusion:** In VSCode, I integrated the model into a captivating Streamlit app. This interactive interface invited users to input feature values, yielding instantaneous predictions for housing prices as well as seeing the map.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7b4083",
   "metadata": {},
   "source": [
    "# Build and Save the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb34a2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "\n",
    "# Load your dataset (replace 'data.csv' with your dataset file)\n",
    "data = pd.read_csv('melb_data.csv')\n",
    "\n",
    "# Handle missing values (this is just an example, you may need a more sophisticated imputation strategy)\n",
    "data.fillna(data.mean(), inplace=True)\n",
    "\n",
    "# Define features and target variable\n",
    "X = data.drop('Price', axis=1)\n",
    "y = data['Price']\n",
    "\n",
    "# Define features and target variable\n",
    "X = data.drop('Price', axis=1)\n",
    "y = data['Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5677a51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define numeric and categorical columns\n",
    "numeric_columns = ['Rooms', 'Distance', 'Bathroom', 'Landsize', 'BuildingArea', 'YearBuilt', 'Car']\n",
    "categorical_columns = ['Suburb', 'Type', 'Regionname']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2053d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "# Create a ColumnTransformer for preprocessing\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_columns),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_columns)  # Handle unknown categories\n",
    "    ])\n",
    "\n",
    "\n",
    "# Create a pipeline with preprocessing and RandomForestRegressor\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('rf_model', RandomForestRegressor(n_estimators=100, random_state=123))  \n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b07c381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 80045129697.74\n"
     ]
    }
   ],
   "source": [
    "# Fit the pipeline on the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation data\n",
    "y_pred = pipeline.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "print(f\"Mean Squared Error: {mse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe72682f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['housing_pipeline.joblib']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the pipeline to a joblib file\n",
    "joblib.dump(pipeline, 'housing_pipeline.joblib')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35023bbe",
   "metadata": {},
   "source": [
    "# Check the Model and Version of Scikit-Learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95a08491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[851585.]\n"
     ]
    }
   ],
   "source": [
    "# I am going to check the model using a sample case \n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "# Load the pipeline from the joblib file\n",
    "loaded_pipeline = joblib.load('housing_pipeline.joblib')\n",
    "\n",
    "# Create a dictionary with the feature values for prediction\n",
    "# Example values, replace with your own numbers\n",
    "input_data = {\n",
    "    'Rooms': 3,\n",
    "    'Distance': 10,\n",
    "    'Bathroom': 2,\n",
    "    'Landsize': 600,\n",
    "    'BuildingArea': 150,\n",
    "    'YearBuilt': 2000,\n",
    "    'Car': 2,\n",
    "    'Suburb': 'SuburbName',\n",
    "    'Type': 'h',\n",
    "    'Regionname': 'RegionName'\n",
    "}\n",
    "\n",
    "# Convert the dictionary into a DataFrame\n",
    "input_df = pd.DataFrame([input_data])\n",
    "\n",
    "# Make predictions using the loaded pipeline\n",
    "predictions = loaded_pipeline.predict(input_df)\n",
    "\n",
    "# Display the predictions\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26e82576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Price: $851,585\n"
     ]
    }
   ],
   "source": [
    "# Make predictions using the loaded pipeline\n",
    "predictions = loaded_pipeline.predict(input_df)\n",
    "\n",
    "# Format the predictions for better readability\n",
    "formatted_predictions = [\"${:,.0f}\".format(prediction) for prediction in predictions]\n",
    "\n",
    "print(f\"Predicted Price: {prediction}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56b58824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.2\n"
     ]
    }
   ],
   "source": [
    "# It is extremly important to check the version of SciKit-Learn since Streamlit only works with the same version in VSCode. \n",
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dafb0f4",
   "metadata": {},
   "source": [
    "# Extract Useful Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "307ef589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Abbotsford' 'Airport West' 'Albert Park' 'Alphington' 'Altona'\n",
      " 'Altona North' 'Armadale' 'Ascot Vale' 'Ashburton' 'Ashwood'\n",
      " 'Avondale Heights' 'Balaclava' 'Balwyn' 'Balwyn North' 'Bentleigh'\n",
      " 'Bentleigh East' 'Box Hill' 'Braybrook' 'Brighton' 'Brighton East'\n",
      " 'Brunswick' 'Brunswick West' 'Bulleen' 'Burwood' 'Camberwell'\n",
      " 'Canterbury' 'Carlton North' 'Carnegie' 'Caulfield' 'Caulfield North'\n",
      " 'Caulfield South' 'Chadstone' 'Clifton Hill' 'Coburg' 'Coburg North'\n",
      " 'Collingwood' 'Doncaster' 'Eaglemont' 'Elsternwick' 'Elwood' 'Essendon'\n",
      " 'Essendon North' 'Fairfield' 'Fitzroy' 'Fitzroy North' 'Flemington'\n",
      " 'Footscray' 'Glen Iris' 'Glenroy' 'Gowanbrae' 'Hadfield' 'Hampton'\n",
      " 'Hampton East' 'Hawthorn' 'Heidelberg Heights' 'Heidelberg West'\n",
      " 'Hughesdale' 'Ivanhoe' 'Kealba' 'Keilor East' 'Kensington' 'Kew'\n",
      " 'Kew East' 'Kooyong' 'Maidstone' 'Malvern' 'Malvern East' 'Maribyrnong'\n",
      " 'Melbourne' 'Middle Park' 'Mont Albert' 'Moonee Ponds' 'Moorabbin'\n",
      " 'Newport' 'Niddrie' 'North Melbourne' 'Northcote' 'Oak Park'\n",
      " 'Oakleigh South' 'Parkville' 'Pascoe Vale' 'Port Melbourne' 'Prahran'\n",
      " 'Preston' 'Reservoir' 'Richmond' 'Rosanna' 'Seddon' 'South Melbourne'\n",
      " 'South Yarra' 'Southbank' 'Spotswood' 'St Kilda' 'Strathmore' 'Sunshine'\n",
      " 'Sunshine North' 'Sunshine West' 'Surrey Hills' 'Templestowe Lower'\n",
      " 'Thornbury' 'Toorak' 'Viewbank' 'Watsonia' 'West Melbourne'\n",
      " 'Williamstown' 'Williamstown North' 'Windsor' 'Yallambie' 'Yarraville'\n",
      " 'Aberfeldie' 'Bellfield' 'Brunswick East' 'Burnley' 'Campbellfield'\n",
      " 'Carlton' 'East Melbourne' 'Essendon West' 'Fawkner' 'Hawthorn East'\n",
      " 'Heidelberg' 'Ivanhoe East' 'Jacana' 'Kingsbury' 'Kingsville'\n",
      " 'Murrumbeena' 'Ormond' 'West Footscray' 'Albion' 'Brooklyn' 'Glen Huntly'\n",
      " 'Oakleigh' 'Ripponlea' 'Cremorne' 'Docklands' 'South Kingsville'\n",
      " 'Strathmore Heights' 'Travancore' 'Caulfield East' 'Seaholme'\n",
      " 'Keilor Park' 'Gardenvale' 'Princes Hill' 'Bayswater' 'Bayswater North'\n",
      " 'Beaumaris' 'Berwick' 'Boronia' 'Briar Hill' 'Broadmeadows' 'Bundoora'\n",
      " 'Burnside Heights' 'Burwood East' 'Cairnlea' 'Caroline Springs'\n",
      " 'Cheltenham' 'Craigieburn' 'Cranbourne' 'Croydon' 'Dandenong'\n",
      " 'Dandenong North' 'Diamond Creek' 'Dingley Village' 'Doncaster East'\n",
      " 'Donvale' 'Doreen' 'Eltham' 'Epping' 'Forest Hill' 'Frankston'\n",
      " 'Frankston North' 'Frankston South' 'Gisborne' 'Gladstone Park'\n",
      " 'Greensborough' 'Hallam' 'Healesville' 'Highett' 'Hillside' 'Huntingdale'\n",
      " 'Keilor Downs' 'Keilor Lodge' 'Keysborough' 'Kings Park' 'Lalor'\n",
      " 'Lower Plenty' 'Melton' 'Mernda' 'Mill Park' 'Mitcham' 'Montmorency'\n",
      " 'Mordialloc' 'Mount Waverley' 'Narre Warren' 'Nunawading' 'Oakleigh East'\n",
      " 'Parkdale' 'Point Cook' 'Ringwood East' 'Rockbank' 'Rowville'\n",
      " 'Sandringham' 'Seaford' 'Skye' 'South Morang' 'Springvale' 'St Albans'\n",
      " 'Sunbury' 'Tarneit' 'Taylors Hill' 'Taylors Lakes' 'The Basin'\n",
      " 'Thomastown' 'Truganina' 'Tullamarine' 'Vermont' 'Wantirna'\n",
      " 'Wantirna South' 'Werribee' 'Westmeadows' 'Williams Landing' 'Wollert'\n",
      " 'Wyndham Vale' 'Black Rock' 'Blackburn' 'Blackburn North' 'Bonbeach'\n",
      " 'Carrum' 'Chelsea' 'Clayton' 'Doveton' 'Ferntree Gully' 'Glen Waverley'\n",
      " 'Greenvale' 'Heathmont' 'Hoppers Crossing' 'McKinnon' 'Melton South'\n",
      " 'Melton West' 'Mentone' 'Mooroolbark' 'Mulgrave' 'Ringwood'\n",
      " 'Roxburgh Park' 'Seabrook' 'Templestowe' 'Vermont South' 'Warrandyte'\n",
      " 'Watsonia North' 'Wheelers Hill' 'Altona Meadows' 'Blackburn South'\n",
      " 'Carrum Downs' 'Clayton South' 'Croydon North' 'Langwarrin' 'Noble Park'\n",
      " 'Notting Hill' 'Ringwood North' 'Sydenham' 'Albanvale'\n",
      " 'Beaconsfield Upper' 'Chelsea Heights' 'Dallas' 'Deer Park'\n",
      " 'Eltham North' 'Keilor' 'Meadow Heights' 'Mount Evelyn'\n",
      " 'North Warrandyte' 'Pakenham' 'Riddells Creek' 'Sandhurst' 'Scoresby'\n",
      " 'Silvan' 'Aspendale' 'Chirnside Park' 'Croydon Hills' 'Croydon South'\n",
      " 'Derrimut' 'Diggers Rest' 'Edithvale' 'Hampton Park' 'Knoxfield'\n",
      " 'St Helena' 'Upwey' 'Bacchus Marsh' 'Coolaroo' 'Cranbourne North'\n",
      " 'Kilsyth' 'Montrose' 'Aspendale Gardens' 'Bullengarook' 'Clarinda'\n",
      " 'Deepdene' 'Delahey' 'Hurstbridge' 'Kurunjang' 'Wonga Park'\n",
      " 'Endeavour Hills' 'Officer' 'Waterways' 'Ardeer' 'Beaconsfield'\n",
      " 'Springvale South' 'Yarra Glen' 'Brookfield' 'Emerald' 'Whittlesea'\n",
      " 'Burnside' 'Attwood' 'Wallan' 'New Gisborne' 'Plumpton' 'Monbulk']\n",
      "['Northern Metropolitan' 'Western Metropolitan' 'Southern Metropolitan'\n",
      " 'Eastern Metropolitan' 'South-Eastern Metropolitan' 'Eastern Victoria'\n",
      " 'Northern Victoria' 'Western Victoria']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('melb_data.csv')\n",
    "\n",
    "unique_suburbs = data['Suburb'].unique()\n",
    "print(unique_suburbs)\n",
    "\n",
    "unique_suburbs = data['Regionname'].unique()\n",
    "print(unique_suburbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab5ba2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a134e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vp": {
   "vp_config_version": "1.0.0",
   "vp_menu_width": 273,
   "vp_note_display": false,
   "vp_note_width": 0,
   "vp_position": {
    "width": 278
   },
   "vp_section_display": false,
   "vp_signature": "VisualPython"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
